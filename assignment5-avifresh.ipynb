{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 248 Assignment 5\n",
    "\n",
    "**Author:** _Manasa Kudumu_\n",
    "**Date:** _Feb 27, 2025_\n",
    "\n",
    "**Table of Content**\n",
    "\n",
    "1. [Part 1: Getting the menus from Wellesley Fresh](#sec1)\n",
    "2. [Part 2: Working with the menu data](#sec2)\n",
    "\n",
    "[Link to Github Repo](https://github.com/Wellesley-CS248/assignment-5-wellesley-fresh-manasakudumu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "\n",
    "### Part 1: Getting the menus from Wellesley Fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: creating wellesley-dining.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # bae pao\n",
    "# url1 = \"https://dish.avifoodsystems.com/wellesley/96/148/week\"\n",
    "# url2 = \"https://dish.avifoodsystems.com/wellesley/96/149/week\"\n",
    "# url3 = \"https://dish.avifoodsystems.com/wellesley/96/312/week\"\n",
    "\n",
    "# #bates\n",
    "# url4 = \"https://dish.avifoodsystems.com/wellesley/95/145/week\"\n",
    "# url5 =\"https://dish.avifoodsystems.com/wellesley/95/146/week\"\n",
    "# url6 =\"https://dish.avifoodsystems.com/wellesley/95/311/week\"\n",
    "\n",
    "# # stone d\n",
    "# url7 =\"https://dish.avifoodsystems.com/wellesley/131/261/week\"\n",
    "# url8 =\"https://dish.avifoodsystems.com/wellesley/131/262/week\"\n",
    "# url9 =\"https://dish.avifoodsystems.com/wellesley/131/263/week\"\n",
    "\n",
    "# #tower\n",
    "# url10 =\"https://dish.avifoodsystems.com/wellesley/97/153/week\"\n",
    "# url11 =\"https://dish.avifoodsystems.com/wellesley/97/154/week\"\n",
    "# url12 =\"https://dish.avifoodsystems.com/wellesley/97/310/week\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: define a function, get_menu, which takes three parameters: a date, a location ID, and a meal ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_menu(date, locationID , mealID):\n",
    "    base_url = \"https://dish.avifoodsystems.com/wellesley\"\n",
    "    url = f\"{base_url}/{locationID}/{mealID}/{date.replace('-', '/')}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: write_menus, which takes two parameters: the CSV filename we created in Task 1 and a date. Then, this function will call the function get_menu as many times as needed to get the menu for each row of the CSV, and each time dump the data into a new JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_menus(file, date ):\n",
    "    with open(file, \"r\") as f:\n",
    "        csvr = csv.DictReader(f)\n",
    "    \n",
    "        for i in csvr:\n",
    "            location = i['location']\n",
    "            meal = i['meal']\n",
    "            locationID = i['locationID']\n",
    "            mealID = i['mealID']\n",
    "            menu = get_menu(date, locationID, mealID)\n",
    "            \n",
    "            if menu:\n",
    "                jsonf = f\"{location}-{meal}-{date}.json\"\n",
    "                with open(jsonf, \"w\") as ff:\n",
    "                    json.dump(menu, ff)\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04-02-2025'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.now().date()\n",
    "today.strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: checking of the results, especially with respect to their completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 rows in Bao-Breakfast-02-20-2025.json\n",
      "111 rows in Bao-Dinner-02-20-2025.json\n",
      "119 rows in Bao-Lunch-02-20-2025.json\n",
      "71 rows in Bates-Breakfast-02-20-2025.json\n",
      "146 rows in Bates-Dinner-02-20-2025.json\n",
      "156 rows in Bates-Lunch-02-20-2025.json\n",
      "48 rows in StoneD-Breakfast-02-20-2025.json\n",
      "56 rows in StoneD-Dinner-02-20-2025.json\n",
      "96 rows in StoneD-Lunch-02-20-2025.json\n",
      "42 rows in Tower-Breakfast-02-20-2025.json\n",
      "120 rows in Tower-Dinner-02-20-2025.json\n",
      "106 rows in Tower-Lunch-02-20-2025.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    " \n",
    "files = os.listdir(\"provided-jsons\") \n",
    "json_files = sorted([file for file in files if file.endswith(\".json\")])\n",
    "for file in json_files:\n",
    "        file_path = os.path.join(\"provided-jsons\", file)  \n",
    "        with open(file_path, \"r\") as jsonf:\n",
    "                data = json.load(jsonf)  \n",
    "                print(f\"{len(data)} rows in {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "\n",
    "### Part 2: Working with the menu data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: merge df together using pd.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appeded Bao-Breakfast-02-20-2025.json. Now size is (59, 12)\n",
      "Appeded Bao-Dinner-02-20-2025.json. Now size is (170, 12)\n",
      "Appeded Bao-Lunch-02-20-2025.json. Now size is (289, 12)\n",
      "Appeded Bates-Breakfast-02-20-2025.json. Now size is (360, 12)\n",
      "Appeded Bates-Dinner-02-20-2025.json. Now size is (506, 12)\n",
      "Appeded Bates-Lunch-02-20-2025.json. Now size is (662, 12)\n",
      "Appeded StoneD-Breakfast-02-20-2025.json. Now size is (710, 12)\n",
      "Appeded StoneD-Dinner-02-20-2025.json. Now size is (766, 12)\n",
      "Appeded StoneD-Lunch-02-20-2025.json. Now size is (862, 12)\n",
      "Appeded Tower-Breakfast-02-20-2025.json. Now size is (904, 12)\n",
      "Appeded Tower-Dinner-02-20-2025.json. Now size is (1024, 12)\n",
      "Appeded Tower-Lunch-02-20-2025.json. Now size is (1130, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "files = os.listdir(\"provided-jsons\")\n",
    "json_files = sorted([file for file in files if file.endswith(\".json\")])\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(\"provided-jsons\", file)\n",
    "    df1 = pd.read_json(file_path)\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    print(f\"Appeded {file}. Now size is {df.shape}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Using pandas commands  for dropping columns, rows, and fixing the two columns “allergens” and “preferences”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1130, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLess = df.drop(columns=['date', 'image', 'stationName', 'stationOrder', 'price'])\n",
    "dfLess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal = dfLess.drop_duplicates(subset=['id'], keep='first')\n",
    "dfFinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(cellLst):\n",
    "    result = \"\"\n",
    "    if cellLst:\n",
    "        result = \",\".join([item['name'] for item in cellLst])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>description</th>\n",
       "      <th>categoryName</th>\n",
       "      <th>stationName</th>\n",
       "      <th>stationOrder</th>\n",
       "      <th>allergens</th>\n",
       "      <th>preferences</th>\n",
       "      <th>price</th>\n",
       "      <th>nutritionals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16472</td>\n",
       "      <td>Breakfast Bowl with Sausage</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td>Scrambled eggs topped with sausage, home fries...</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td>Soy,Dairy,Egg</td>\n",
       "      <td>Gluten Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'id': 230891, 'servingSize': '6.00', 'serving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20985</td>\n",
       "      <td>Caramelized Onions (Oil)</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Misc</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Vegan,Gluten Sensitive,Vegetarian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'id': 229549, 'servingSize': '1.02', 'serving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15890</td>\n",
       "      <td>Home Fry Potatoes</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td>Crispy seasoned diced breakfast potatoes.</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td>Soy,Dairy</td>\n",
       "      <td>Gluten Sensitive,Vegetarian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'id': 233526, 'servingSize': '4.00', 'serving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19875</td>\n",
       "      <td>Pork Sausage Link</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td>Pork breakfast sausage link.</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Gluten Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'id': 228338, 'servingSize': '0.80', 'serving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19611</td>\n",
       "      <td>Sauteed Spinach</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td>Sautéed baby spinach with minced onion and gar...</td>\n",
       "      <td>Misc</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Vegan,Gluten Sensitive,Vegetarian,NutriGOOD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'id': 231288, 'servingSize': '2.38', 'serving...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                         name       date image  \\\n",
       "0  16472  Breakfast Bowl with Sausage 2025-02-17         \n",
       "1  20985     Caramelized Onions (Oil) 2025-02-17         \n",
       "2  15890            Home Fry Potatoes 2025-02-17         \n",
       "3  19875            Pork Sausage Link 2025-02-17         \n",
       "4  19611              Sauteed Spinach 2025-02-17         \n",
       "\n",
       "                                         description categoryName stationName  \\\n",
       "0  Scrambled eggs topped with sausage, home fries...    Breakfast   BREAKFAST   \n",
       "1                                                            Misc   BREAKFAST   \n",
       "2          Crispy seasoned diced breakfast potatoes.    Breakfast   BREAKFAST   \n",
       "3                       Pork breakfast sausage link.    Breakfast   BREAKFAST   \n",
       "4  Sautéed baby spinach with minced onion and gar...         Misc   BREAKFAST   \n",
       "\n",
       "   stationOrder      allergens                                  preferences  \\\n",
       "0             4  Soy,Dairy,Egg                             Gluten Sensitive   \n",
       "1             4                           Vegan,Gluten Sensitive,Vegetarian   \n",
       "2             4      Soy,Dairy                  Gluten Sensitive,Vegetarian   \n",
       "3             4                                            Gluten Sensitive   \n",
       "4             4                 Vegan,Gluten Sensitive,Vegetarian,NutriGOOD   \n",
       "\n",
       "   price                                       nutritionals  \n",
       "0    0.0  {'id': 230891, 'servingSize': '6.00', 'serving...  \n",
       "1    0.0  {'id': 229549, 'servingSize': '1.02', 'serving...  \n",
       "2    0.0  {'id': 233526, 'servingSize': '4.00', 'serving...  \n",
       "3    0.0  {'id': 228338, 'servingSize': '0.80', 'serving...  \n",
       "4    0.0  {'id': 231288, 'servingSize': '2.38', 'serving...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['allergens'] = df['allergens'].apply(transform) # notice, we don't pass any arguments to the function here\n",
    "df['preferences'] = df['preferences'].apply(transform)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: separating nutritionals into different columns and then dropping nutritionals column at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['servingSize'] = df['nutritionals'].apply(lambda d: float(d['servingSize']) if d and d['servingSize'] else np.nan)\n",
    "df['servingSizeUOM'] = df['nutritionals'].apply(lambda d: d['servingSizeUOM'] if d else np.nan)\n",
    "df['calories'] = df['nutritionals'].apply(lambda d: float(d['calories']) if d and d['calories'] else np.nan)\n",
    "df['fat'] = df['nutritionals'].apply(lambda d: float(d['fat']) if d and d['fat'] else np.nan)\n",
    "df['caloriesFromFat'] = df['nutritionals'].apply(lambda d: float(d['caloriesFromFat']) if d and d['caloriesFromFat'] else np.nan)\n",
    "df['saturatedFat'] = df['nutritionals'].apply(lambda d: float(d['saturatedFat']) if d and d['saturatedFat'] else np.nan)\n",
    "df['transFat'] = df['nutritionals'].apply(lambda d: float(d['transFat']) if d and d['transFat'] else np.nan)\n",
    "df['cholesterol'] = df['nutritionals'].apply(lambda d: float(d['cholesterol']) if d and d['cholesterol'] else np.nan)\n",
    "df['sodium'] = df['nutritionals'].apply(lambda d: float(d['sodium']) if d and d['sodium'] else np.nan)\n",
    "df['carbohydrates'] = df['nutritionals'].apply(lambda d: float(d['carbohydrates']) if d and d['carbohydrates'] else np.nan)\n",
    "df['dietaryFiber'] = df['nutritionals'].apply(lambda d: float(d['dietaryFiber']) if d and d['dietaryFiber'] else np.nan)\n",
    "df['sugars'] = df['nutritionals'].apply(lambda d: float(d['sugars']) if d and d['sugars'] else np.nan)\n",
    "df['addedSugar'] = df['nutritionals'].apply(lambda d: float(d['addedSugar']) if d and d['addedSugar'] else np.nan)\n",
    "df['protein'] = df['nutritionals'].apply(lambda d: float(d['protein']) if d and d['protein'] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['nutritionals'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"wellesley-meals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>description</th>\n",
       "      <th>categoryName</th>\n",
       "      <th>stationName</th>\n",
       "      <th>stationOrder</th>\n",
       "      <th>allergens</th>\n",
       "      <th>preferences</th>\n",
       "      <th>...</th>\n",
       "      <th>caloriesFromFat</th>\n",
       "      <th>saturatedFat</th>\n",
       "      <th>transFat</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>sodium</th>\n",
       "      <th>carbohydrates</th>\n",
       "      <th>dietaryFiber</th>\n",
       "      <th>sugars</th>\n",
       "      <th>addedSugar</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16472</td>\n",
       "      <td>Breakfast Bowl with Sausage</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td>Scrambled eggs topped with sausage, home fries...</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td>Soy,Dairy,Egg</td>\n",
       "      <td>Gluten Sensitive</td>\n",
       "      <td>...</td>\n",
       "      <td>335.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20985</td>\n",
       "      <td>Caramelized Onions (Oil)</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Misc</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Vegan,Gluten Sensitive,Vegetarian</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15890</td>\n",
       "      <td>Home Fry Potatoes</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td>Crispy seasoned diced breakfast potatoes.</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td>Soy,Dairy</td>\n",
       "      <td>Gluten Sensitive,Vegetarian</td>\n",
       "      <td>...</td>\n",
       "      <td>149.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19875</td>\n",
       "      <td>Pork Sausage Link</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td>Pork breakfast sausage link.</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Gluten Sensitive</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19611</td>\n",
       "      <td>Sauteed Spinach</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td></td>\n",
       "      <td>Sautéed baby spinach with minced onion and gar...</td>\n",
       "      <td>Misc</td>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Vegan,Gluten Sensitive,Vegetarian,NutriGOOD</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                         name       date image  \\\n",
       "0  16472  Breakfast Bowl with Sausage 2025-02-17         \n",
       "1  20985     Caramelized Onions (Oil) 2025-02-17         \n",
       "2  15890            Home Fry Potatoes 2025-02-17         \n",
       "3  19875            Pork Sausage Link 2025-02-17         \n",
       "4  19611              Sauteed Spinach 2025-02-17         \n",
       "\n",
       "                                         description categoryName stationName  \\\n",
       "0  Scrambled eggs topped with sausage, home fries...    Breakfast   BREAKFAST   \n",
       "1                                                            Misc   BREAKFAST   \n",
       "2          Crispy seasoned diced breakfast potatoes.    Breakfast   BREAKFAST   \n",
       "3                       Pork breakfast sausage link.    Breakfast   BREAKFAST   \n",
       "4  Sautéed baby spinach with minced onion and gar...         Misc   BREAKFAST   \n",
       "\n",
       "   stationOrder      allergens                                  preferences  \\\n",
       "0             4  Soy,Dairy,Egg                             Gluten Sensitive   \n",
       "1             4                           Vegan,Gluten Sensitive,Vegetarian   \n",
       "2             4      Soy,Dairy                  Gluten Sensitive,Vegetarian   \n",
       "3             4                                            Gluten Sensitive   \n",
       "4             4                 Vegan,Gluten Sensitive,Vegetarian,NutriGOOD   \n",
       "\n",
       "   ...  caloriesFromFat  saturatedFat transFat  cholesterol  sodium  \\\n",
       "0  ...            335.0           9.0      0.0        286.0   670.0   \n",
       "1  ...             68.0           0.0      0.0          0.0     5.0   \n",
       "2  ...            149.0           3.0      0.0          0.0   596.0   \n",
       "3  ...            130.0           5.0      0.0         21.0   170.0   \n",
       "4  ...             61.0           0.0      0.0          0.0    61.0   \n",
       "\n",
       "   carbohydrates  dietaryFiber  sugars  addedSugar  protein  \n",
       "0            9.0           1.0     2.0         0.0     15.0  \n",
       "1           11.0           2.0     5.0         0.0      1.0  \n",
       "2           19.0           2.0     1.0         0.0      2.0  \n",
       "3            1.0           0.0     0.0         0.0      3.0  \n",
       "4            3.0           2.0     0.0         0.0      2.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfFinal.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
